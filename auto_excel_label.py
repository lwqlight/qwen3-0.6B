import pandas as pd
import torch
import json
import re
import sys
import os
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel

# =================é…ç½®åŒºåŸŸ=================
# è¾“å…¥æ–‡ä»¶ï¼šåªåŒ…å« 'Input_Text' ä¸€åˆ—çš„ Excel
INPUT_EXCEL = "./data/test/raw_inputs.xlsx"       
# è¾“å‡ºæ–‡ä»¶ï¼šæ¨¡å‹å¡«å¥½æ•°æ®çš„ Excel
OUTPUT_EXCEL = "./data/test/human_data_labeled.xlsx" 

# æ¨¡å‹è·¯å¾„é…ç½®
BASE_MODEL_PATH = "./qwen3-0.6B"
# æŒ‡å‘ä½ çš„ LoRA æƒé‡è·¯å¾„
LORA_PATH = "./finetune_model/qwen3_0.6B_smarthome_mutil_instruct" 

# ç»Ÿä¸€æŒ‡ä»¤ (å¿…é¡»ä¸è®­ç»ƒæ—¶ä¸€è‡´)
UNIFIED_INSTRUCTION = "æ™ºèƒ½å®¶å±…ä¸­æ§ï¼šæå–ç”¨æˆ·æŒ‡ä»¤ä¸­çš„å®ä½“ä¸æ„å›¾ï¼Œè¾“å‡ºæ ‡å‡†çš„JSONæ§åˆ¶ä»£ç ã€‚"
# =========================================

# --- 1. åŠ è½½æ¨¡å‹ (PyTorch åŸç”Ÿ) ---
print("ğŸš€ æ­£åœ¨åŠ è½½ PyTorch æ¨¡å‹...")
try:
    # åŠ è½½ Tokenizer
    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH, trust_remote_code=True)

    # åŠ è½½åŸºåº§
    base_model = AutoModelForCausalLM.from_pretrained(
        BASE_MODEL_PATH,
        device_map="auto",
        torch_dtype=torch.float16,
        trust_remote_code=True
    )

    # åŠ è½½ LoRA
    model = PeftModel.from_pretrained(base_model, LORA_PATH)
    model.eval() # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")

except Exception as e:
    print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    sys.exit(1)

# --- 2. æ ¸å¿ƒï¼šæ¨ç†å‡½æ•° ---
def predict_labels(user_input):
    # æ„é€  Prompt
    user_content = f"ä»»åŠ¡ï¼š{UNIFIED_INSTRUCTION}\næŒ‡ä»¤ï¼š{user_input}"
    
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½å®¶å±…ä¸­æ§åŠ©æ‰‹ï¼Œè¯·å°†ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŒ‡ä»¤è½¬æ¢ä¸ºJSONæ ¼å¼çš„æ§åˆ¶ä»£ç ã€‚"},
        {"role": "user", "content": user_content}
    ]

    try:
        text = tokenizer.apply_chat_template(
            messages, 
            tokenize=False, 
            add_generation_prompt=True,
            enable_thinking=False 
        )
    except TypeError:
        text = tokenizer.apply_chat_template(
            messages, 
            tokenize=False, 
            add_generation_prompt=True
        )

    model_inputs = tokenizer([text], return_tensors="pt").to(base_model.device)

    with torch.no_grad():
        generated_ids = model.generate(
            **model_inputs,
            max_new_tokens=512, # è¶³å¤Ÿå®¹çº³å¤šä»»åŠ¡æŒ‡ä»¤
            temperature=0.1,    # ä½æ¸©ä¿è¯æ ¼å¼ç¨³å®š
            top_p=0.9,
            do_sample=True
        )

    # è§£æè¾“å‡º (å»é™¤è¾“å…¥çš„ prompt)
    input_len = model_inputs.input_ids.shape[1]
    new_tokens = generated_ids[0][input_len:]
    content = tokenizer.decode(new_tokens, skip_special_tokens=True).strip()
    return content

# --- 3. è¾…åŠ©ï¼šJSON æå–å™¨ ---
def extract_json(text):
    try:
        # ä¼˜å…ˆæ‰¾åˆ—è¡¨ [...]
        match_list = re.search(r'\[.*\]', text, re.DOTALL)
        if match_list: 
            return json.loads(match_list.group())
        
        # å†æ‰¾å¯¹è±¡ {...}
        match_dict = re.search(r'\{.*\}', text, re.DOTALL)
        if match_dict: 
            # ç»Ÿä¸€è½¬ä¸ºåˆ—è¡¨è¿”å›ï¼Œæ–¹ä¾¿åç»­å¤„ç†
            return [json.loads(match_dict.group())] 
    except:
        pass
    return None

# --- 4. ä¸»ä¸šåŠ¡é€»è¾‘ï¼šè¯»å– Excel -> æ ‡æ³¨ -> ä¿å­˜ ---
def auto_label():
    print(f"ğŸ“‚ è¯»å–åŸå§‹æ•°æ®æ–‡ä»¶: {INPUT_EXCEL}")
    if not os.path.exists(INPUT_EXCEL):
        print("âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ï¼Œè¯·å…ˆåˆ›å»ºä¸€ä¸ªåä¸º raw_inputs.xlsx çš„è¡¨æ ¼ï¼ŒåŒ…å« 'Input_Text' åˆ—ã€‚")
        return

    try:
        df = pd.read_excel(INPUT_EXCEL)
    except Exception as e:
        print(f"âŒ è¯»å– Excel å¤±è´¥: {e}")
        return

    # å‡†å¤‡ç»“æœå®¹å™¨
    labeled_rows = []
    total = len(df)
    
    print(f"âš¡ å¼€å§‹è‡ªåŠ¨æ ‡æ³¨ï¼Œå…± {total} æ¡æ•°æ®...")

    for index, row in df.iterrows():
        input_text = str(row['Input_Text']).strip()
        # è·³è¿‡ç©ºè¡Œ
        if not input_text or input_text.lower() == 'nan':
            continue

        print(f"[{index+1}/{total}] å¤„ç†: {input_text}")

        # --- è°ƒç”¨æ¨¡å‹æ¨ç† ---
        raw_output = predict_labels(input_text)
        
        # --- æå– JSON ---
        json_data = extract_json(raw_output)

        if json_data:
            # å¦‚æœè§£ææˆåŠŸï¼Œéå†ç»“æœï¼ˆå…¼å®¹å¤šä»»åŠ¡æŒ‡ä»¤ç”Ÿæˆå¤šè¡Œï¼‰
            for item in json_data:
                labeled_rows.append({
                    "Input_Text": input_text,
                    "Target": item.get("target", ""),
                    "Action": item.get("action", ""),
                    "Value": item.get("value", "")
                })
        else:
            # å¦‚æœè§£æå¤±è´¥ï¼Œå¡«å…¥åŸå§‹å†…å®¹ï¼Œæ ‡è®°ä¸ºå¾…äººå·¥æ£€æŸ¥
            print(f"  âš ï¸ æ¨¡å‹è¾“å‡ºæ ¼å¼å¼‚å¸¸ï¼Œéœ€äººå·¥å¡«å†™: {raw_output}")
            labeled_rows.append({
                "Input_Text": input_text,
                "Target": "MANUAL_CHECK", # æ ‡è®°å…³é”®è¯
                "Action": raw_output,     # æŠŠåŸå§‹è¾“å‡ºå¡«è¿›å»å‚è€ƒ
                "Value": ""
            })

    # --- ä¿å­˜ç»“æœ ---
    print("ğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœ...")
    result_df = pd.DataFrame(labeled_rows)
    result_df.to_excel(OUTPUT_EXCEL, index=False)
    
    print("\n" + "="*50)
    print(f"âœ… è‡ªåŠ¨æ ‡æ³¨å®Œæˆï¼")
    print(f"ğŸ“‚ ç»“æœæ–‡ä»¶: {OUTPUT_EXCEL}")
    print("âš ï¸  ä¸‹ä¸€æ­¥ï¼šè¯·åŠ¡å¿…æ‰“å¼€è¡¨æ ¼è¿›è¡Œäººå·¥æ ¡éªŒï¼Œä¿®æ­£ 'MANUAL_CHECK' åŠé”™è¯¯çš„æ ‡æ³¨ï¼")
    print("="*50)

if __name__ == "__main__":
    auto_label()